# -*- coding: utf-8 -*-
"""diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xu3YvrjpY3kZjLiBFSxTVFYldQWxFmu3
"""

import pandas as pd
import matplotlib.pyplot as plt
import joblib
import numpy as np

from sklearn.preprocessing import StandardScaler

from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score

df = pd.read_csv('diabetes.csv')
df.head()

# Some columns contain zeros that actually represent missing data.
# We replace them with the mean or median of the column.
columns_with_zero = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]

for col in columns_with_zero:
    df[col] = df[col].replace(0, df[col].median())

df.hist(figsize=(10,8))
plt.show()

# Standardization
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df.drop("Outcome", axis=1))

# K-Means with 3 clusters
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Add cluster to dataframe
df['Cluster'] = clusters

cluster_summary = df.groupby('Cluster').mean()
print(cluster_summary)

# Features : All columns except Outcome
X = df.drop("Outcome", axis=1)
y = df["Outcome"]

# Separate train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Save Random Forest model
joblib.dump(rf_model, "diabetes_model.pkl")

# Save scaler
joblib.dump(scaler, "scaler.pkl")